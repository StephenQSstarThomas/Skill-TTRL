"""
Skill Merger: external LLM that merges winning samples' skill operations.

After majority voting selects k winning samples, the merger:
1. Merges generated skills (dedup + fuse)
2. Merges retrieved skills (find most commonly used subset)
3. Merges evolved skills (combine improvement directions)
"""

from __future__ import annotations

import json
import logging
from dataclasses import dataclass, field
from typing import Optional

logger = logging.getLogger(__name__)


@dataclass
class MergedSkillOps:
    """Result of merging k winning samples' skill operations."""
    new_skills: list[dict] = field(default_factory=list)
    useful_retrieval_ids: list[str] = field(default_factory=list)
    evolved_skills: list[tuple[str, dict]] = field(default_factory=list)
    merge_summary: str = ""


# Prompt templates for the external LLM
_MERGE_GENERATE_PROMPT = """\
You are a skill synthesis expert. Below are {n} skill descriptions generated by \
different model samples that all arrived at the correct answer for the same problem.

Your task: merge and deduplicate these skills into the best, most concise set of \
new skills. Remove redundancy, combine overlapping ideas, and keep only genuinely \
novel and useful insights.

## Generated skills from winning samples:

{skills_text}

## Instructions:
- Output a JSON array of merged skills
- Each skill: {{"title": "...", "content": "..."}}
- Aim for the minimal set that captures all unique insights
- Do NOT include skills that are trivially obvious

Output ONLY the JSON array, no other text."""

_MERGE_RETRIEVE_PROMPT = """\
Below are the skill IDs retrieved by {n} different model samples that all answered \
correctly. Some skills were retrieved by multiple samples (likely more useful), \
while others by only one (possibly noise).

## Retrieval records:
{retrieval_text}

## Instructions:
- Identify the minimal, most useful subset of retrieved skill IDs
- Skills retrieved by more samples are more likely useful
- Output a JSON array of skill IDs (strings)

Output ONLY the JSON array, no other text."""

_MERGE_EVOLVE_PROMPT = """\
Below are {n} different evolved versions of existing skills, all produced by samples \
that answered correctly. Each evolution improves an existing skill in a different direction.

## Evolution records:
{evolve_text}

## Instructions:
- For each base skill that was evolved, merge the improvements into one best version
- Take the best ideas from each evolution
- Output a JSON array of {{"base_id": "...", "title": "...", "content": "..."}}

Output ONLY the JSON array, no other text."""


class SkillMerger:
    """
    Merges skill operations from winning samples using an external LLM.

    Supports both OpenAI-compatible APIs and a local fallback (heuristic-based).
    """

    def __init__(
        self,
        model: str = "gpt-4o",
        api_key: Optional[str] = None,
        api_base: Optional[str] = None,
        max_tokens: int = 2048,
        temperature: float = 0.3,
        use_api: bool = True,
    ):
        self.model = model
        self.api_key = api_key
        self.api_base = api_base
        self.max_tokens = max_tokens
        self.temperature = temperature
        self.use_api = use_api
        self._client = None

    def _get_client(self):
        if self._client is None and self.use_api:
            try:
                from openai import OpenAI
                kwargs = {}
                if self.api_key:
                    kwargs["api_key"] = self.api_key
                if self.api_base:
                    kwargs["base_url"] = self.api_base
                self._client = OpenAI(**kwargs)
            except ImportError:
                logger.warning("openai package not installed, using heuristic merge")
                self.use_api = False
        return self._client

    def _call_llm(self, prompt: str) -> str:
        """Call the external LLM."""
        client = self._get_client()
        if client is None:
            raise RuntimeError("No LLM client available")

        response = client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=self.max_tokens,
            temperature=self.temperature,
        )
        return response.choices[0].message.content.strip()

    def _parse_json_response(self, text: str) -> list:
        """Extract JSON array from LLM response."""
        # Try direct parse
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            pass

        # Try extracting from markdown code block
        import re
        match = re.search(r"```(?:json)?\s*\n?(.*?)\n?```", text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1))
            except json.JSONDecodeError:
                pass

        # Try finding array in text
        match = re.search(r"\[.*\]", text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(0))
            except json.JSONDecodeError:
                pass

        logger.warning(f"Could not parse JSON from LLM response: {text[:200]}")
        return []

    # ------------------------------------------------------------------
    # Main merge entry point
    # ------------------------------------------------------------------
    def merge(
        self,
        winning_outputs: list,  # list of ParsedOutput from winning samples
    ) -> MergedSkillOps:
        """
        Merge skill operations from winning samples.

        Args:
            winning_outputs: ParsedOutput objects from samples matching majority vote.

        Returns:
            MergedSkillOps with deduplicated/fused results.
        """
        result = MergedSkillOps()

        # Collect ops from winners
        generates = [
            o.skill_ops.generate
            for o in winning_outputs
            if o.skill_ops.has_generate
        ]
        retrieves = [
            (o.skill_ops.retrieve_query, o.skill_ops.retrieve_results)
            for o in winning_outputs
            if o.skill_ops.has_retrieve
        ]
        evolves = [
            (o.skill_ops.evolve_base_id, o.skill_ops.evolve_content)
            for o in winning_outputs
            if o.skill_ops.has_evolve
        ]

        # Merge each type
        if generates:
            result.new_skills = self._merge_generates(generates)

        if retrieves:
            result.useful_retrieval_ids = self._merge_retrieves(retrieves)

        if evolves:
            result.evolved_skills = self._merge_evolves(evolves)

        ops_done = []
        if result.new_skills:
            ops_done.append(f"{len(result.new_skills)} new skills")
        if result.useful_retrieval_ids:
            ops_done.append(f"{len(result.useful_retrieval_ids)} useful retrievals")
        if result.evolved_skills:
            ops_done.append(f"{len(result.evolved_skills)} evolved skills")
        result.merge_summary = ", ".join(ops_done) if ops_done else "no ops"

        return result

    # ------------------------------------------------------------------
    # Individual merge methods
    # ------------------------------------------------------------------
    def _merge_generates(self, generates: list[str]) -> list[dict]:
        """Merge generated skills from winning samples."""
        if self.use_api:
            try:
                return self._api_merge_generates(generates)
            except Exception as e:
                logger.warning(f"API merge failed: {e}, using heuristic")

        return self._heuristic_merge_generates(generates)

    def _api_merge_generates(self, generates: list[str]) -> list[dict]:
        skills_text = "\n\n".join(
            f"### Sample {i+1}:\n{g}" for i, g in enumerate(generates)
        )
        prompt = _MERGE_GENERATE_PROMPT.format(
            n=len(generates), skills_text=skills_text
        )
        response = self._call_llm(prompt)
        return self._parse_json_response(response)

    def _heuristic_merge_generates(self, generates: list[str]) -> list[dict]:
        """Simple deduplication: keep unique skills based on content similarity."""
        seen = set()
        result = []
        for g in generates:
            key = g.strip().lower()[:100]
            if key not in seen:
                seen.add(key)
                result.append({
                    "title": g.strip().split("\n")[0][:80],
                    "content": g.strip(),
                })
        return result

    def _merge_retrieves(self, retrieves: list[tuple[str, str]]) -> list[str]:
        """Merge retrieved skill sets: skills used by more winners are more useful."""
        if self.use_api:
            try:
                return self._api_merge_retrieves(retrieves)
            except Exception as e:
                logger.warning(f"API merge failed: {e}, using heuristic")

        return self._heuristic_merge_retrieves(retrieves)

    def _api_merge_retrieves(self, retrieves: list[tuple[str, str]]) -> list[str]:
        retrieval_text = "\n\n".join(
            f"### Sample {i+1} (query: \"{q}\"):\n{r}"
            for i, (q, r) in enumerate(retrieves)
        )
        prompt = _MERGE_RETRIEVE_PROMPT.format(
            n=len(retrieves), retrieval_text=retrieval_text
        )
        response = self._call_llm(prompt)
        return self._parse_json_response(response)

    def _heuristic_merge_retrieves(
        self, retrieves: list[tuple[str, str]]
    ) -> list[str]:
        """Count skill ID mentions across samples; keep those mentioned by >50%."""
        import re
        id_counts: dict[str, int] = {}
        for _, results_text in retrieves:
            ids = re.findall(r"#(\w+)", results_text)
            for sid in ids:
                id_counts[sid] = id_counts.get(sid, 0) + 1

        threshold = max(1, len(retrieves) // 2)
        return [sid for sid, count in id_counts.items() if count >= threshold]

    def _merge_evolves(
        self, evolves: list[tuple[str, str]]
    ) -> list[tuple[str, dict]]:
        """Merge evolution results for the same base skill."""
        if self.use_api:
            try:
                return self._api_merge_evolves(evolves)
            except Exception as e:
                logger.warning(f"API merge failed: {e}, using heuristic")

        return self._heuristic_merge_evolves(evolves)

    def _api_merge_evolves(
        self, evolves: list[tuple[str, str]]
    ) -> list[tuple[str, dict]]:
        evolve_text = "\n\n".join(
            f"### Sample {i+1} (base: #{base_id}):\n{content}"
            for i, (base_id, content) in enumerate(evolves)
        )
        prompt = _MERGE_EVOLVE_PROMPT.format(
            n=len(evolves), evolve_text=evolve_text
        )
        response = self._call_llm(prompt)
        parsed = self._parse_json_response(response)
        return [
            (item.get("base_id", ""), item) for item in parsed
        ]

    def _heuristic_merge_evolves(
        self, evolves: list[tuple[str, str]]
    ) -> list[tuple[str, dict]]:
        """Group by base_id, keep the longest (most detailed) evolution."""
        from collections import defaultdict
        by_base: dict[str, list[str]] = defaultdict(list)
        for base_id, content in evolves:
            by_base[base_id].append(content)

        result = []
        for base_id, contents in by_base.items():
            best = max(contents, key=len)
            result.append((
                base_id,
                {"title": f"Evolved #{base_id}", "content": best},
            ))
        return result
